<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ZeroSC-SR: Importance-Aware Zero-Shot Semantic Speech Communication over Fading Channels</title>
  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    .audio-sample {
      margin: 10px 0;
    }
    /* Larger, bolder main section titles */
    .section-title {
      @apply text-3xl font-bold mb-4;
    }
    /* Larger, bolder subsection titles */
    .subsection-title {
      @apply text-2xl font-bold mb-2;
    }
  </style>
</head>

<body class="bg-gray-50">
  <!-- Container -->
  <div class="container mx-auto px-4 py-8 max-w-4xl">
    
    <!-- Header -->
    <header class="text-center mb-12">
      <h1 class="text-4xl font-bold mb-4">
        ZeroSC-SR: Importance-Aware Zero-Shot Semantic Speech Communication over Fading Channels
      </h1>
      <div class="text-center">
        <p class="font-medium">Zewei Wang, Guanchong Niu, Yao Tang, Tat Ming Lok, Man-On Pun</p>
      </div>
      <p class="text-sm text-gray-600">
        Contact: <span class="font-medium">Zewei Wang</span> (<em>zwwong at link.cuhk.edu.hk</em>)
      </p>
    </header>
    
    <!-- Table of Contents -->
    <nav class="mb-12 bg-white border rounded p-4 shadow">
      <h2 class="text-xl font-bold mb-4">Table of Contents</h2>
      <ul class="list-disc list-inside text-gray-700 ml-4">
        <li><a href="#abstract" class="text-blue-600 hover:underline">Abstract</a></li>
        <li>
          <a href="#proposed-system" class="text-blue-600 hover:underline">Proposed System</a>
          <ul class="list-decimal list-inside ml-6">
            <li>
              <a href="#transmitter" class="text-blue-600 hover:underline">
                Transmitter
              </a>
            </li>
            <li>
              <a href="#iiaps-strategy" class="text-blue-600 hover:underline">
                Iterative Importance-Aware Allocation and Power Scheduling Strategy
              </a>
            </li>
            <li>
              <a href="#receiver" class="text-blue-600 hover:underline">
                Receiver
              </a>
            </li>
          </ul>
        </li>
        <li>
          <a href="#experiment-results" class="text-blue-600 hover:underline">
            Experiment and Numerical Results
          </a>
          <ul class="list-decimal list-inside ml-6">
            <li><a href="#prompt-length" class="text-blue-600 hover:underline">Prompt Length</a></li>
            <li><a href="#phoneme-acoustic" class="text-blue-600 hover:underline">Phonemes vs. Acoustic Features</a></li>
            <li><a href="#iiaps-analysis" class="text-blue-600 hover:underline">IIAPS Strategy Analysis</a></li>
            <li><a href="#comparison-models" class="text-blue-600 hover:underline">Comparison With Other Models</a></li>
          </ul>
        </li>
        <li><a href="#code" class="text-blue-600 hover:underline">Code</a></li>
        <li><a href="#references" class="text-blue-600 hover:underline">References</a></li>
      </ul>
    </nav>

    <!-- Abstract -->
    <section id="abstract" class="mb-12">
      <h2 class="section-title">Abstract</h2>
      <p class="text-gray-700">
      Advancements in artificial intelligence have enabled the development of more efficient and semantic-aware speech communication systems. 
      This paper introduces an innovative Zero-Shot Semantic Communication System with Speech Reconstruction (ZeroSC-SR), designed to enhance speech transmission and reconstruction in frequency-selective fading channels. 
      By efficiently transmitting phoneme sequences and compressed prompt acoustic features, ZeroSC-SR achieves a high compression ratio and reduces transmitted data size, enabling superior performance under low-power and noisy conditions. 
      We investigate the impact of prompt length on recognition accuracy and system performance, identifying a trade-off between performance and energy efficiency and offering practical guidelines for selecting appropriate prompt lengths.
      We quantitatively evaluate the semantic importance of intermediate transmission data, encompassing phoneme sequences and acoustic features, through a task-oriented Mutual-Information-based approach.
      These insights directly guide the development of our Iterative Importance-Aware Allocation and Power Scheduling strategy, which enhances transmission quality in frequency-selective fading channels by allocating channel resources based on semantic importance.
      Experimental results show that ZeroSC-SR surpasses conventional speech communication systems, demonstrating its effectiveness in real-world applications that demand reliable and efficient speech communication over challenging channels.
      </p>
    </section>

    <figure class="mb-4">
      <img src="Fig/overview.svg" alt="Proposed System Diagram" class="w-full rounded shadow" />
      <figcaption class="text-center text-sm text-gray-600 mt-2">
        Figure 1: Overview of the ZeroSC-SR system structure.
      </figcaption>
    </figure>

    <!-- Proposed System -->
    <section id="proposed-system" class="mb-12">
      <h2 class="section-title">Proposed System</h2>
      <p class="text-gray-700 mb-4">
        The proposed ZeroSC-SR framework combines semantic (phoneme-level) and acoustic (prompt audio codec) features 
        to enable efficient digital speech transmission under frequency-selective fading channels. 
      </p>

      <!-- (1) Transmitter -->
      <h3 id="transmitter" class="subsection-title">1) Transmitter</h3>
      <p class="text-gray-700 mb-4">
        At the transmitter, speech is split into:
      </p>
      <ul class="list-disc list-inside text-gray-700 mb-4 ml-6">
        <li>
          <strong>Phoneme Identifiers:</strong> Capturing essential linguistic elements
          via ASR-based phonemization.
        </li>
        <li>
          <strong>Prompt Audio Codec Codes:</strong> Extracted by selecting a short
          speech prompt and compressing it through the Audio Codec Model [R1].
        </li>
      </ul>
      <p class="text-gray-700 mb-4">
        These data streams are evaluated by the mutual-information-based task-oriented approach, then converted into binary sequences and protected
        with error-control coding (e.g., LDPC), followed by modulation (e.g., 4-QAM).
      </p>
      <figure class="mb-4">
        <img src="Fig/channel_encoder.svg" alt="Channel Encoder Diagram" class="w-full rounded shadow"/>
        <figcaption class="text-center text-sm text-gray-600 mt-2">
          Figure 2: Channel Encoder Diagram.
        </figcaption>
      </figure>

      <!-- (2) IIAPS Strategy -->
      <h3 id="iiaps-strategy" class="subsection-title">
        2) Iterative Importance-Aware Allocation and Power Scheduling Strategy
      </h3>
      <p class="text-gray-700 mb-4">
        To combat frequency-selective fading, ZeroSC-SR employs an Iterative Importance-Aware Allocation and Power Scheduling (IIAPS) strategy, optimizing the assignment of data streams to subcarriers and power distribution to maximize transmission reliability while balancing intelligibility and speaker fidelity within a fixed power budget.
      </p>
      <p class="text-gray-700 mb-4">
        <strong>Problem Formulation:</strong> The goal is to maximize the reliability of transmitting critical data streams over multiple subcarriers, weighted by their importance to the tasks of speech intelligibility and speaker fidelity. Importance weights are derived from a mutual-information-based approach, with a user-defined parameter balancing these objectives. The system ensures each subcarrier carries at most one stream, uses non-negative power, and adheres to a total power limit, accounting for channel gains and noise levels.
      </p>
      <p class="text-gray-700 mb-4">
        <strong>IIAPS Solution:</strong> The complex optimization problem is addressed iteratively:
      </p>
      <ol class="list-roman list-inside text-gray-700 mb-4 ml-6">
        <li>
          <strong>Initial Assignment:</strong> Data streams are prioritized by their importance, and subcarriers are ranked by their channel quality. High-importance streams are paired with high-quality subcarriers to create an initial assignment.
        </li>
        <li>
          <strong>Power Allocation:</strong> Power is distributed across assigned subcarriers using a water-filling approach, allocating more power to streams based on their importance and channel conditions, while respecting the total power constraint.
        </li>
        <li>
          <strong>Refinement:</strong> The system iteratively evaluates swapping stream-subcarrier assignments, accepting changes that improve overall reliability, until no further improvements are possible.
        </li>
      </ol>
      <p class="text-gray-700 mb-4">
        This iterative process ensures efficient and reliable transmission by aligning stream importance with channel quality and power allocation, achieving a local optimum with low computational complexity [R7].
      </p>

      <!-- (3) Receiver -->
      <h3 id="receiver" class="subsection-title">3) Receiver</h3>
      <p class="text-gray-700 mb-4">
        The receiver reverses the transmitter steps, demodulating and decoding the data
        streams. Phoneme IDs and audio codec codes are recovered and mapped to their
        original order based on stored index information. Finally, the VALL-E
        model [R2] predicts the remaining codec codes, and the Audio Codec decoder
        reconstructs the full speech waveform [R1]. This integrated pipeline
        enables a zero-shot capability for unseen speakers, achieving high-quality
        performance in low-power and noisy scenarios.
      </p>
    </section>

    <!-- Experiment and Numerical Results -->
    <section id="experiment-results" class="mb-12">
      <h2 class="section-title">Experiment and Numerical Results</h2>
      <p class="text-gray-700 mb-6">
        The performance of the proposed system is evaluated under varying channel conditions. Experiments are conducted using the Libri-light dataset [R3] on an NVIDIA RTX A4000. The evaluation metrics, including the CER, WER [R4], and speaker similarity [R5], provide insights into the system’s semantic understanding and speaker fidelity.
        We utilize three pre-trained models: Whisper [R6] for automatic speech recognition, EnCodec [R1] for audio codec model, and VALL-E [R2] for zero-shot speech synthesis.
      </p>

      <!-- Experiment Parameters Table -->
      <div class="overflow-auto mb-6">
        <table class="min-w-full bg-white border border-gray-300 text-gray-700">
          <thead class="bg-gray-100 border-b">
            <tr>
              <th class="py-2 px-4 text-left">Parameter</th>
              <th class="py-2 px-4 text-left">Value</th>
              <th class="py-2 px-4 text-left">Notes</th>
            </tr>
          </thead>
          <tbody>
            <tr class="border-b">
              <td class="py-2 px-4">Error Control Coding</td>
              <td class="py-2 px-4">LDPC</td>
              <td class="py-2 px-4">---</td>
            </tr>
            <tr class="border-b">
              <td class="py-2 px-4">Modulation Scheme</td>
              <td class="py-2 px-4">4-QAM</td>
              <td class="py-2 px-4">---</td>
            </tr>
            <tr class="border-b">
              <td class="py-2 px-4">Input Speech Length</td>
              <td class="py-2 px-4">~10 seconds</td>
              <td class="py-2 px-4">---</td>
            </tr>
            <tr class="border-b">
              <td class="py-2 px-4">Prompt Length</td>
              <td class="py-2 px-4">2 seconds</td>
              <td class="py-2 px-4">
                <a href="#prompt-length" class="text-blue-600 hover:underline">Sec. IV.A</a>
              </td>
            </tr>
            <tr class="border-b">
              <td class="py-2 px-4">SNR Range</td>
              <td class="py-2 px-4">[-5, 15] dB</td>
              <td class="py-2 px-4">
                <a href="#phoneme-acoustic" class="text-blue-600 hover:underline">Sec. IV.B</a>
              </td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- 1) Prompt Length -->
      <h3 id="prompt-length" class="subsection-title">1) Prompt Length</h3>
      <p class="text-gray-700 mb-4">
        The length of the transmitted prompt impacts both system performance and the required transmission resources. Therefore, we seek to determine an appropriate prompt length that reduces transmission resource usage while maintaining satisfactory system performance.
      </p>

      <!-- Audio Samples for Prompt Length -->
      <p class="text-gray-700 mb-4">
        Below are audio samples from the final system output at different prompt lengths (1s, 2s, and 3s).
      </p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-8">
        <div class="audio-sample">
          <p class="font-medium mb-2">Prompt = 1s</p>
          <p class="text-sm text-gray-600 mb-2">
             For prompts under two seconds, insufficient acoustic cues and higher recognition errors degrade performance.
          </p>
          <audio controls class="w-full">
            <source src="audio/Length/1s/121_127105_000008_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">Prompt = 2s</p>
          <p class="text-sm text-gray-600 mb-2">
            The 2-second prompt length balances performance and efficiency and is selected as a practical compromise.
          </p>
          <audio controls class="w-full">
            <source src="audio/Length/2s/121_127105_000008_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">Prompt = 3s</p>
          <p class="text-sm text-gray-600 mb-2">
            For prompts > 2s, the prompt provides sufficient information, resulting in excellent overall performance.
          </p>
          <audio controls class="w-full">
            <source src="audio/Length/3s/121_127105_000008_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <!-- 2) Phonemes vs. Acoustic Features -->
      <h3 id="phoneme-acoustic" class="subsection-title">2) Phonemes vs. Acoustic Features</h3>
      <p class="text-gray-700 mb-4">
        ZeroSC-SR simultaneously handles <strong>phoneme transmission</strong> (carrying semantic content) and <strong>acoustic feature transmission</strong> (audio codec codes capturing speaker characteristics). 
        To illustrate their sensitivity to channel noise, we provide separate audio samples at 0 dB, 5 dB, and 10 dB for each transmission type:
      </p>
      <ul class="list-disc list-inside text-gray-700 mb-4 ml-4">
        <li><strong>Phonemes:</strong> Errors in phoneme data severely affect CER/WER.</li>
        <li><strong>Acoustic Features:</strong> Distorted audio codec codes lead to loss of speaker similarity.</li>
      </ul>

      <!-- Audio Samples for Phoneme Transmission -->
      <p class="font-semibold mt-4 mb-2 text-gray-800">Phonemes are transmitted through a noisy channel while acoustic features remain noiseless</p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 0 dB</p>
          <p class="text-sm text-gray-600 mb-2">
            Very Bad.
          </p>
          <audio controls class="w-full">
            <source src="audio/Phoneme_Acoustic_SNR/0dB_phoneme/121_127105_000008_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 5 dB</p>
          <p class="text-sm text-gray-600 mb-2">
            Poor.
          </p>
          <audio controls class="w-full">
            <source src="audio/Phoneme_Acoustic_SNR/5dB_phoneme/121_127105_000008_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 10 dB</p>
          <p class="text-sm text-gray-600 mb-2">
            Good.
          </p>
          <audio controls class="w-full">
            <source src="audio/Phoneme_Acoustic_SNR/10dB_phoneme/121_127105_000008_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <!-- Audio Samples for Acoustic Feature Transmission -->
      <p class="font-semibold mt-4 mb-2 text-gray-800"> Acoustic features are transmitted with noise and phonemes are noiseless.</p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-8">
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 0 dB</p>
          <p class="text-sm text-gray-600 mb-2">
            Poor. 
          </p>
          <audio controls class="w-full">
            <source src="audio/Phoneme_Acoustic_SNR/0dB_acoustic/121_127105_000008_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 5 dB</p>
          <p class="text-sm text-gray-600 mb-2">
            Acceptable. 
          </p>
          <audio controls class="w-full">
            <source src="audio/Phoneme_Acoustic_SNR/5dB_acoustic/121_127105_000008_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 10 dB</p>
          <p class="text-sm text-gray-600 mb-2">
            Good. 
          </p>
          <audio controls class="w-full">
            <source src="audio/Phoneme_Acoustic_SNR/10dB_acoustic/121_127105_000008_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <p class="text-gray-700 mb-4">
        Phonemes exhibit higher noise sensitivity (critical SNR: 5–10 dB) than acoustic features (critical SNR: 0–5 dB). 
      </p>

      <!-- 3) IIAPS Strategy Analysis -->
      <h3 id="iiaps-analysis" class="subsection-title">3) IIAPS Strategy Analysis</h3>
      <p class="text-gray-700 mb-4">
        The IIAPS strategy is evaluated by transmitting nine semantic streams (one phoneme stream and eight audio codec stages from a 2-second prompt) over 20 OFDM subcarriers, with a fixed power budget and SNR ranging from -5 dB to 15 dB. The setup assumes perfect channel state information and equal weighting for intelligibility and speaker fidelity.
      </p>
      <p class="text-gray-700 mb-4">
        <strong>Comparison Strategies:</strong>
      </p>
      <ul class="list-disc list-inside text-gray-700 mb-4 ml-4">
        <li><strong>Random-Uniform:</strong> Randomly assigns streams to subcarriers with uniform power distribution.</li>
        <li><strong>Random-WF:</strong> Uses random assignments but allocates power based on channel quality.</li>
        <li><strong>Greedy-WF:</strong> Pairs high-importance streams with high-quality subcarriers, then applies power allocation based on channel quality.</li>
      </ul>
      <!-- Audio Samples for IIAPS Strategy Analysis -->
      <p class="text-gray-700 mb-4">
        Below are system outputs at 5 dB, 10 dB, and 15 dB for IIAPS, Random-Uniform, Random-WF, and Greedy-WF.
      </p>
      <!-- IIAPS Strategy -->
      <p class="font-semibold mt-4 mb-2 text-gray-800">IIAPS Strategy</p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 5 dB</p>
          <p class="text-sm text-gray-600 mb-2">Satisfactory.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/IIAPS/5dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 10 dB</p>
          <p class="text-sm text-gray-600 mb-2">Good.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/IIAPS/10dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 15 dB</p>
          <p class="text-sm text-gray-600 mb-2">Very Good.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/IIAPS/15dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>
      <!-- Random-Uniform Strategy -->
      <p class="font-semibold mt-4 mb-2 text-gray-800">Random-Uniform Strategy</p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 5 dB</p>
          <p class="text-sm text-gray-600 mb-2">Very Bad.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/Random-Uniform/5dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 10 dB</p>
          <p class="text-sm text-gray-600 mb-2">Poor.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/Random-Uniform/10dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 15 dB</p>
          <p class="text-sm text-gray-600 mb-2">Satisfactory.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/Random-Uniform/15dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>
      <!-- Random-WF Strategy -->
      <p class="font-semibold mt-4 mb-2 text-gray-800">Random-WF Strategy</p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 5 dB</p>
          <p class="text-sm text-gray-600 mb-2">Very Bad.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/Random-WF/5dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 10 dB</p>
          <p class="text-sm text-gray-600 mb-2">Poor.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/Random-WF/10dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 15 dB</p>
          <p class="text-sm text-gray-600 mb-2">Satisfactory.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/Random-WF/15dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>
      <!-- Greedy-WF Strategy -->
      <p class="font-semibold mt-4 mb-2 text-gray-800">Greedy-WF Strategy</p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 5 dB</p>
          <p class="text-sm text-gray-600 mb-2">Poor.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/Greedy-WF/5dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 10 dB</p>
          <p class="text-sm text-gray-600 mb-2">Satisfactory.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/Greedy-WF/10dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 15 dB</p>
          <p class="text-sm text-gray-600 mb-2">Good.</p>
          <audio controls class="w-full">
            <source src="audio/IIAPS_Upload/Greedy-WF/15dB/237_126133_000010_000000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <!-- 4) Comparison With Other Models -->
      <h3 id="comparison-models" class="subsection-title">4) Comparison With Other Models</h3>
      <p class="text-gray-700 mb-4">
        We benchmark ZeroSC-SR against EnCodec and LPC. Our system achieves the highest compression ratio while maintaining robust performance in low-power conditions. Though all systems converge at high power levels, ZeroSC-SR excels in challenging environments, retaining both semantic content and speaker identity when channel quality is poor.
      </p>

      <!-- Concise addition about experimental setup -->
      <p class="text-gray-700 mb-4">
        In our setup, total power, duration, and noise PSD are constant across all systems, with sufficient bandwidth 
        for fixed transmission time. Consequently, larger data size leads to lower energy per bit (due to higher data rate), 
        reducing SNR per bit and affecting overall performance.
      </p>
      
      <!-- Audio Samples for Comparison With Other Models -->
      <p class="text-gray-700 mb-4">
        Below are placeholder samples comparing ZeroSC-SR, EnCodec, and LPC at different power levels. 
        Observe how ZeroSC-SR preserves good system performance at lower power, whereas EnCodec and LPC generally require higher power to achieve comparable performance.
      </p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4">
        <!-- ZeroSC-SR (1W, 10W, 100W) -->
        <div class="audio-sample">
          <p class="font-medium mb-2">ZeroSC-SR @ 1W</p>
          <audio controls class="w-full">
            <source src="audio/Model_Compare/ZeroSC-SR/power1/121_127105_000016_000006.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">ZeroSC-SR @ 10W</p>
          <audio controls class="w-full">
            <source src="audio/Model_Compare/ZeroSC-SR/power10/121_127105_000016_000006.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">ZeroSC-SR @ 100W</p>
          <audio controls class="w-full">
            <source src="audio/Model_Compare/ZeroSC-SR/power100/121_127105_000016_000006.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>
      
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mt-4">
        <!-- EnCodec (1W, 10W, 100W) -->
        <div class="audio-sample">
          <p class="font-medium mb-2">EnCodec @ 1W</p>
          <audio controls class="w-full">
            <source src="audio/Model_Compare/EnCodec/121_127105_000016_000006_power1.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">EnCodec @ 10W</p>
          <audio controls class="w-full">
            <source src="audio/Model_Compare/EnCodec/121_127105_000016_000006_power10.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">EnCodec @ 100W</p>
          <audio controls class="w-full">
            <source src="audio/Model_Compare/EnCodec/121_127105_000016_000006_power100.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mt-4">
        <!-- LPC (10^3 W, 10^4 W, 10^5 W) -->
        <div class="audio-sample">
          <p class="font-medium mb-2">LPC @ 10^3 W</p>
          <p class="text-sm text-gray-600 mb-2">
              Be careful, the sound is harsh, turn it down.
          </p>
          <audio controls class="w-full">
            <source src="audio/Model_Compare/LPC/8230_279154_000006_000001_power1000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">LPC @ 10^4 W</p>
          <p class="text-sm text-gray-600 mb-2">
              Be careful, the sound is harsh, turn it down.
          </p>
          <audio controls class="w-full">
            <source src="audio/Model_Compare/LPC/8230_279154_000006_000001_power10000.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">LPC @ 10^5 W</p>
          <audio controls class="w-full">
            <source src="audio/Model_Compare/LPC/8230_279154_000006_000001_power100000order4.wav" type="audio/wav" />
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>
    </section>

    <!-- Code -->
    <section id="code" class="mb-12">
      <h2 class="section-title">Code</h2>
      <p class="text-gray-700 mb-4">
        The complete source code for ZeroSC-SR is publicly available. Feel free to clone the repository and follow the instructions in the README to reproduce our experiments and audio demonstrations.
      </p>
      <a href="https://github.com/WinfredCU/ZeroSC-SR.git" class="text-blue-600 hover:underline">
        GitHub Repository
      </a>
    </section>

    <!-- References -->
    <section id="references" class="mb-12">
      <h2 class="section-title">References</h2>
      <ol class="list-decimal list-inside text-gray-700 ml-6">
        <li>
          <strong>[R1]</strong> Défossez, A., Copet, J., Synnaeve, G., & Adi, Y. (2022).
          "High Fidelity Neural Audio Compression." 
          <em>arXiv preprint arXiv:2210.13438</em>.
        </li>
        <li>
          <strong>[R2]</strong> Wang, C. et al. (2023). 
          "Neural Codec Language Models Are Zero-Shot Text to Speech Synthesizers," 
          <em>arXiv preprint arXiv:2301.02111</em>.
        </li>
        <li>
          <strong>[R3]</strong> Panayotov, V., Chen, G., Povey, D., & Khudanpur, S. (2015).
          "Librispeech: An ASR corpus based on public domain audio books."
          <em>2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.
        </li>
        <li>
          <strong>[R4]</strong> Klakow, D., & Peters, J. (2002).
          "Testing the correlation of word error rate and perplexity."
          <em>Speech Communication, 38(1-2), 19-28</em>.
        </li>
        <li>
          <strong>[R5]</strong> Chen, S., Wang, C., Chen, Z., Wu, Y., Liu, S., Chen, Z., ... & Watanabe, S. (2022).
          "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing."
          <em>IEEE Journal of Selected Topics in Signal Processing, 16(6), 1505-1518</em>.
        </li>
        <li>
          <strong>[R6]</strong> Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., & Sutskever, I. (2023).
          "Robust Speech Recognition via Large-Scale Weak Supervision."
          <em>arXiv preprint arXiv:2212.04356</em>.
        </li>
        <li>
          <strong>[R7]</strong> Goldsmith, A. (2005).
          "Wireless Communications."
          <em>Cambridge University Press</em>.
        </li>
      </ol>
    </section>

    <!-- Footer -->
    <footer class="mt-12 text-center text-gray-500 text-sm">
      <p class="mb-2">© Wang Zewei</p>
    </footer>
  </div>
</body>
</html>
