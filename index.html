<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ZeroSC-SR Paper Demo</title>
  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    .audio-sample {
      margin: 10px 0;
    }
    .section-title {
      @apply text-2xl font-bold mb-4;
    }
    .subsection-title {
      @apply text-xl font-bold mb-2;
    }
  </style>
</head>

<body class="bg-gray-50">

  <!-- Container -->
  <div class="container mx-auto px-4 py-8 max-w-4xl">
    
    <!-- Header -->
    <header class="text-center mb-12">
      <h1 class="text-4xl font-bold mb-4">ZeroSC-SR: Leveraging Data Importance for Efficient Semantic Speech Communication</h1>
      <div class="flex flex-wrap justify-center gap-4 mb-2">
        <div class="text-center">
          <p class="font-medium">Zewei Wang</p>
        </div>
        <div class="text-center">
          <p class="font-medium">Guanchong Niu</p>
        </div>
        <div class="text-center">
          <p class="font-medium">Yao Tang</p>
        </div>
        <div class="text-center">
          <p class="font-medium">Man-On Pun</p>
        </div>
        <div class="text-center">
          <p class="font-medium">Tat Ming Lok</p>
        </div>
      </div>
      <p class="text-sm text-gray-600">
        Contact: <span class="font-medium">Zewei Wang</span> (<em>zwwong at link.cuhk.edu.hk</em>)
      </p>
    </header>

    <!-- Table of Contents -->
    <nav class="mb-12 bg-white border rounded p-4 shadow">
      <h2 class="text-xl font-bold mb-4">Table of Contents</h2>
      <ul class="list-disc list-inside text-gray-700 ml-4">
        <li><a href="#abstract" class="text-blue-600 hover:underline">Abstract</a></li>
        <li><a href="#proposed-system" class="text-blue-600 hover:underline">Proposed System</a></li>
        <li>
          <a href="#experiment-results" class="text-blue-600 hover:underline">
            Experiment and Numerical Results
          </a>
          <ul class="list-decimal list-inside ml-6">
            <li><a href="#prompt-length" class="text-blue-600 hover:underline">Prompt Length</a></li>
            <li><a href="#phoneme-acoustic" class="text-blue-600 hover:underline">Phonemes vs. Acoustic Features</a></li>
            <li><a href="#importance-analysis" class="text-blue-600 hover:underline">Importance Analysis of Acoustic Features</a></li>
            <li><a href="#sort-match" class="text-blue-600 hover:underline">Sort-Match Strategy Analysis</a></li>
            <li><a href="#comparison-models" class="text-blue-600 hover:underline">Comparison With Other Models</a></li>
          </ul>
        </li>
        <li><a href="#code" class="text-blue-600 hover:underline">Code</a></li>
      </ul>
    </nav>

    <!-- Abstract -->
    <section id="abstract" class="mb-12">
      <h2 class="section-title">Abstract</h2>
      <p class="text-gray-700">
        Advancements in artificial intelligence have enabled the development of more efficient and semantic-aware speech communication systems. 
        This paper introduces an innovative Zero-Shot Semantic Communication System with Speech Reconstruction (ZeroSC-SR), designed to enhance speech transmission and reconstruction in frequency-selective fading channels.
        By efficiently transmitting phoneme IDs and compressed prompt acoustic features, ZeroSC-SR achieves a high compression ratio and reduces transmitted data size, enabling superior performance under low-power and noisy conditions. 
        We investigate the impact of prompt length on recognition accuracy and system performance, identifying a trade-off between performance and energy efficiency and offering practical guidelines for selecting appropriate prompt lengths.
        Analyzing the intermediate transmission data, which includes phoneme IDs and acoustic features at different quantization levels, provides critical insights into their relative importance. These insights directly guide the development of our sort-match strategy, which enhances transmission quality in frequency-selective fading channels by allocating channel resources based on data importance.
        Experimental results show that ZeroSC-SR surpasses conventional speech communication systems, demonstrating its effectiveness in real-world applications that demand reliable and efficient speech communication over challenging channels.
      </p>
    </section>

    <!-- Proposed System -->
    <section id="proposed-system" class="mb-12">
      <h2 class="section-title">Proposed System</h2>
      <p class="text-gray-700 mb-4">
        The ZeroSC-SR system introduces a cutting-edge approach to semantic speech communication, addressing challenges in transmitting speech over frequency-selective fading channels. By combining phoneme-based semantic transmission with advanced audio codec compression, the system achieves efficient data transmission and robust performance under adverse conditions.
      </p>

      <!-- System Model Structure -->
      <h3 class="subsection-title">System Model Structure</h3>
      <ul class="list-disc list-inside text-gray-700 mb-4">
        <li>
          At the <strong>transmitter</strong>, input speech is converted into phoneme IDs and compressed acoustic features using audio codec codes from the EnCodec model.
        </li>
        <li>
          During <strong>channel transmission</strong>, a novel sort-match strategy prioritizes data by importance, optimizing resource allocation under frequency-selective fading conditions.
        </li>
        <li>
          At the <strong>receiver</strong>, phoneme sequences and codec codes are recovered, and the VALL-E model predicts extended codec codes to reconstruct speech using the EnCodec model.
        </li>
      </ul>

      <!-- Contributions -->
      <h3 class="subsection-title">Main Contributions</h3>
      <ul class="list-disc list-inside text-gray-700 mb-4">
        <li>
          <strong>Innovative Zero-Shot Semantic Communication System:</strong> Enables efficient digital transmission of both phonemes and acoustic features over frequency-selective fading channels.
        </li>
        <li>
          <strong>Trade-off Analysis Between Prompt Length and Performance:</strong> Evaluates the influence of prompt length on recognition accuracy and system performance, identifying a practical trade-off between energy efficiency and performance.
        </li>
        <li>
          <strong>Impact Analysis of Intermediate Transmission Data:</strong> Investigates the role of phoneme information and audio codec codes at various quantization levels, guiding the sort-match strategy design.
        </li>
        <li>
          <strong>Novel Sort-Match Strategy:</strong> Allocates subcarriers by ranking data importance to enhance performance in frequency-selective fading channels, outperforming prior frequency-flat fading assumptions.
        </li>
        <li>
          <strong>Efficient Integration with Digital Communication:</strong> Replaces traditional mel spectrograms with audio codec codes for intermediate representation, reducing transmitted data size, and incorporates VALL-E for zero-shot speaker adaptation.
        </li>
      </ul>
      
      <figure class="mb-4">
        <img src="Fig/overview.svg" alt="Proposed System Diagram" class="w-full rounded shadow">
        <figcaption class="text-center text-sm text-gray-600 mt-2">Figure: Overview of the ZeroSC-SR system structure.</figcaption>
      </figure>
    </section>

    <!-- Experiment and Numerical Results -->
    <section id="experiment-results" class="mb-12">
      <h2 class="section-title">Experiment and Numerical Results</h2>
      <p class="text-gray-700 mb-6">
        The performance of the proposed system is evaluated under varying channel conditions, assuming perfect channel state information. Experiments are conducted using the Libri-light dataset on an NVIDIA RTX A4000. Metrics such as Character Error Rate (CER), Word Error Rate (WER), and speaker similarity provide insights into semantic understanding and speaker fidelity. The table below lists key experimental parameters.
      </p>

      <!-- Experiment Parameters Table -->
      <div class="overflow-auto mb-6">
        <table class="min-w-full bg-white border border-gray-300 text-gray-700">
          <thead class="bg-gray-100 border-b">
            <tr>
              <th class="py-2 px-4 text-left">Parameter</th>
              <th class="py-2 px-4 text-left">Value</th>
              <th class="py-2 px-4 text-left">Note/Sections</th>
            </tr>
          </thead>
          <tbody>
            <tr class="border-b">
              <td class="py-2 px-4">Error Control Coding</td>
              <td class="py-2 px-4">LDPC</td>
              <td class="py-2 px-4">---</td>
            </tr>
            <tr class="border-b">
              <td class="py-2 px-4">Modulation Scheme</td>
              <td class="py-2 px-4">4-QAM</td>
              <td class="py-2 px-4">---</td>
            </tr>
            <tr class="border-b">
              <td class="py-2 px-4">Input Speech Length</td>
              <td class="py-2 px-4">~10 seconds</td>
              <td class="py-2 px-4">---</td>
            </tr>
            <tr class="border-b">
              <td class="py-2 px-4">Prompt Length</td>
              <td class="py-2 px-4">2 seconds</td>
              <td class="py-2 px-4"><a href="#prompt-length" class="text-blue-600 hover:underline">Sec. IV.A</a></td>
            </tr>
            <tr class="border-b">
              <td class="py-2 px-4">SNR Range</td>
              <td class="py-2 px-4">[-5, 15] dB</td>
              <td class="py-2 px-4"><a href="#phoneme-acoustic" class="text-blue-600 hover:underline">Sec. IV.B</a></td>
            </tr>
            <tr class="border-b">
              <td class="py-2 px-4">Stages in Audio Codec Codes</td>
              <td class="py-2 px-4">8</td>
              <td class="py-2 px-4"><a href="#importance-analysis" class="text-blue-600 hover:underline">Sec. IV.C</a></td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- 1) Prompt Length -->
      <h3 id="prompt-length" class="subsection-title">1) Prompt Length</h3>
      <p class="text-gray-700 mb-4">
        The length of the transmitted prompt impacts both system performance and the required transmission resources. We aim to determine an appropriate prompt length that reduces resource usage while maintaining satisfactory performance. Experimental results show that increasing the prompt length reduces recognition errors (CER/WER), stabilizing around 2 seconds. After 2 seconds, returns diminish, making 2 seconds a good balance between performance and efficiency.
      </p>

      <!-- Audio Samples for Prompt Length -->
      <p class="text-gray-700 mb-4">
        Below are placeholder audio samples illustrating different prompt lengths (1s, 2s, and 3s). Observe how short prompts might degrade semantic accuracy and speaker fidelity.
      </p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-8">
        <div class="audio-sample">
          <p class="font-medium mb-2">Prompt = 1s</p>
          <p class="text-sm text-gray-600 mb-2">
            Short prompt, possibly causing incomplete word boundaries.
          </p>
          <audio controls class="w-full">
            <source src="audio/PromptLength/1s.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">Prompt = 2s</p>
          <p class="text-sm text-gray-600 mb-2">
            Balanced prompt length for adequate semantic and acoustic info.
          </p>
          <audio controls class="w-full">
            <source src="audio/PromptLength/2s.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">Prompt = 3s</p>
          <p class="text-sm text-gray-600 mb-2">
            Longer prompt, potentially higher accuracy but more data overhead.
          </p>
          <audio controls class="w-full">
            <source src="audio/PromptLength/3s.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <!-- 2) Phonemes vs. Acoustic Features -->
      <h3 id="phoneme-acoustic" class="subsection-title">2) Phonemes vs. Acoustic Features</h3>
      <p class="text-gray-700 mb-4">
        We further investigate the sensitivity of phoneme transmission and acoustic feature transmission to channel noise. Phoneme accuracy significantly affects CER and WER, whereas acoustic features primarily influence speaker similarity. Results indicate that phonemes need higher SNR to preserve semantic content, while acoustic features require decent SNR to maintain speaker fidelity.
      </p>

      <!-- Audio Samples for Phonemes vs. Acoustic Features -->
      <p class="text-gray-700 mb-4">
        The following samples demonstrate system performance at different SNR levels (0 dB, 5 dB, and 10 dB). Listen for semantic clarity (phonemes) vs. acoustic richness (speaker characteristics).
      </p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-8">
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 0 dB</p>
          <p class="text-sm text-gray-600 mb-2">
            Very noisy, phonemes likely to degrade significantly.
          </p>
          <audio controls class="w-full">
            <source src="audio/PhonemeAcoustic/0dB.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 5 dB</p>
          <p class="text-sm text-gray-600 mb-2">
            Moderate noise, affecting both semantic and acoustic features.
          </p>
          <audio controls class="w-full">
            <source src="audio/PhonemeAcoustic/5dB.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 10 dB</p>
          <p class="text-sm text-gray-600 mb-2">
            Less noise, improved accuracy for both phonemes and acoustics.
          </p>
          <audio controls class="w-full">
            <source src="audio/PhonemeAcoustic/10dB.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <!-- 3) Importance Analysis of Acoustic Features -->
      <h3 id="importance-analysis" class="subsection-title">3) Importance Analysis of Acoustic Features</h3>
      <p class="text-gray-700 mb-4">
        We performed a deletion-based experiment on the 8-stage audio codec codes. Removing Stage 1 caused the largest drop in performance across WER, CER, and speaker similarity. Stages 2 and 3 were also influential, but later stages primarily improve speaker fidelity rather than semantic accuracy. This confirms that the initial stages are most crucial.
      </p>

      <!-- Audio Samples for Importance Analysis -->
      <p class="text-gray-700 mb-4">
        Below are sample audios where particular stages (1, 2, and 5) are deleted. Observe how removing earlier stages heavily impacts intelligibility and overall quality.
      </p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-8">
        <div class="audio-sample">
          <p class="font-medium mb-2">Deleting Stage 1</p>
          <p class="text-sm text-gray-600 mb-2">
            Most critical stage removed, major drop in semantic & acoustic fidelity.
          </p>
          <audio controls class="w-full">
            <source src="audio/ImportanceAnalysis/stage1.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">Deleting Stage 2</p>
          <p class="text-sm text-gray-600 mb-2">
            Next most important, moderate effect on speech quality.
          </p>
          <audio controls class="w-full">
            <source src="audio/ImportanceAnalysis/stage2.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">Deleting Stage 5</p>
          <p class="text-sm text-gray-600 mb-2">
            Later stage primarily affects speaker similarity and timbre.
          </p>
          <audio controls class="w-full">
            <source src="audio/ImportanceAnalysis/stage5.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <!-- 4) Sort-Match Strategy Analysis -->
      <h3 id="sort-match" class="subsection-title">4) Sort-Match Strategy Analysis</h3>
      <p class="text-gray-700 mb-4">
        To address frequency-selective fading, we propose sorting data streams by importance (phonemes as highest priority, followed by each codec stage) and matching them to sub-carriers with corresponding gains. Compared with random allocation, our sort-match strategy consistently yields lower CER and WER and maintains higher speaker similarity, even at low SNR.
      </p>

      <!-- Audio Samples for Sort-Match Strategy Analysis -->
      <p class="text-gray-700 mb-4">
        Below are some audio samples illustrating the impact of the sort-match strategy at different SNR levels, compared to the random-match strategy. Listen for differences in intelligibility and speaker clarity.
      </p>
      <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
        <!-- SNR = 5 dB -->
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 5 dB: Sort-Match Strategy</p>
          <p class="text-sm text-gray-600 mb-2">
            Critical data (phonemes, early codec stages) get better subcarriers. Notice better intelligibility in severe noise.
          </p>
          <audio controls class="w-full">
            <source src="audio/Sort_Match/sort/SNR5/121_127105_000016_000006.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 5 dB: Random-Match Strategy</p>
          <p class="text-sm text-gray-600 mb-2">
            Random assignment leads to more pronounced errors and distortion.
          </p>
          <audio controls class="w-full">
            <source src="audio/Sort_Match/random/SNR5/121_127105_000016_000006.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>

        <!-- SNR = 10 dB -->
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 10 dB: Sort-Match Strategy</p>
          <p class="text-sm text-gray-600 mb-2">
            Improved channel quality helps preserve both semantic and acoustic features.
          </p>
          <audio controls class="w-full">
            <source src="audio/Sort_Match/sort/SNR10/121_127105_000016_000006.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 10 dB: Random-Match Strategy</p>
          <p class="text-sm text-gray-600 mb-2">
            Artifacts remain evident without prioritizing important data.
          </p>
          <audio controls class="w-full">
            <source src="audio/Sort_Match/random/SNR10/121_127105_000016_000006.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>

        <!-- SNR = 15 dB -->
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 15 dB: Sort-Match Strategy</p>
          <p class="text-sm text-gray-600 mb-2">
            High SNR with sort-match preserves speaker identity and clarity.
          </p>
          <audio controls class="w-full">
            <source src="audio/Sort_Match/sort/SNR15/121_127105_000016_000006.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">SNR = 15 dB: Random-Match Strategy</p>
          <p class="text-sm text-gray-600 mb-2">
            Even at higher SNR, random assignment lags in fidelity compared to sort-match.
          </p>
          <audio controls class="w-full">
            <source src="audio/Sort_Match/random/SNR15/121_127105_000016_000006.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <!-- 5) Comparison With Other Models -->
      <h3 id="comparison-models" class="subsection-title">5) Comparison With Other Models</h3>
      <p class="text-gray-700 mb-4">
        We benchmark ZeroSC-SR against EnCodec, DeepSC-S, and LPC. Our system achieves the highest compression ratio while maintaining robust performance in low-power conditions. Though all systems converge at high power levels, ZeroSC-SR demonstrates clear advantages in challenging environments where both semantic content and speaker fidelity are crucial.
      </p>

      <!-- Audio Samples for Comparison With Other Models -->
      <p class="text-gray-700 mb-4">
        Below are placeholder samples comparing ZeroSC-SR, EnCodec, and LPC at different power levels. Note how ZeroSC-SR retains quality at lower power, while EnCodec and LPC may require higher power to achieve comparable fidelity.
      </p>
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4">
        <!-- ZeroSC-SR (1W, 10W, 100W) -->
        <div class="audio-sample">
          <p class="font-medium mb-2">ZeroSC-SR @ 1W</p>
          <audio controls class="w-full">
            <source src="audio/Comparison/ZeroSC-SR_1W.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">ZeroSC-SR @ 10W</p>
          <audio controls class="w-full">
            <source src="audio/Comparison/ZeroSC-SR_10W.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">ZeroSC-SR @ 100W</p>
          <audio controls class="w-full">
            <source src="audio/Comparison/ZeroSC-SR_100W.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>
      
      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mt-4">
        <!-- EnCodec (1W, 10W, 100W) -->
        <div class="audio-sample">
          <p class="font-medium mb-2">EnCodec @ 1W</p>
          <audio controls class="w-full">
            <source src="audio/Comparison/EnCodec_1W.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">EnCodec @ 10W</p>
          <audio controls class="w-full">
            <source src="audio/Comparison/EnCodec_10W.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">EnCodec @ 100W</p>
          <audio controls class="w-full">
            <source src="audio/Comparison/EnCodec_100W.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>

      <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mt-4">
        <!-- LPC (10^3 W, 10^4 W, 10^5 W) -->
        <div class="audio-sample">
          <p class="font-medium mb-2">LPC @ 10^3 W</p>
          <audio controls class="w-full">
            <source src="audio/Comparison/LPC_1e3W.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">LPC @ 10^4 W</p>
          <audio controls class="w-full">
            <source src="audio/Comparison/LPC_1e4W.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
        <div class="audio-sample">
          <p class="font-medium mb-2">LPC @ 10^5 W</p>
          <audio controls class="w-full">
            <source src="audio/Comparison/LPC_1e5W.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
        </div>
      </div>
    </section>

    <!-- Code -->
    <section id="code" class="mb-12">
      <h2 class="section-title">Code</h2>
      <p class="text-gray-700 mb-4">
        The complete source code for ZeroSC-SR is publicly available. Feel free to clone the repository and follow the instructions in the README to reproduce our experiments and audio demonstrations.
      </p>
      <a href="https://github.com/WinfredCU/ZeroSC-SR.git" class="text-blue-600 hover:underline">
        GitHub Repository
      </a>
    </section>

    <!-- Footer -->
    <footer class="mt-12 text-center text-gray-500 text-sm">
      <p class="mb-2">
        &copy; 2024 ZeroSC-SR Team
      </p>
    </footer>
  </div>
</body>
</html>
